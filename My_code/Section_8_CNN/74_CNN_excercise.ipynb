{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Exercises\n",
    "For these exercises we'll work with the <a href='https://www.kaggle.com/zalando-research/fashionmnist'>Fashion-MNIST</a> dataset, also available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. Like MNIST, this dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes:\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports, load the Fashion-MNIST dataset\n",
    "Run the cell below to load the libraries needed for this exercise and the Fashion-MNIST dataset.<br>\n",
    "PyTorch makes the Fashion-MNIST dataset available through <a href='https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist'><tt><strong>torchvision</strong></tt></a>. The first time it's called, the dataset will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../Data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../Data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../Data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../Data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='../Data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ../Data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ../Data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt','Trouser','Sweater','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create data loaders\n",
    "Use DataLoader to create a <tt>train_loader</tt> and a <tt>test_loader</tt>. Batch sizes should be 10 for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(x): 10\n",
      "len(x[0][0]): 28\n",
      "len(x[0][0][0]): 28\n",
      "x: tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
      "labels: tensor([2, 7, 5, 8, 4, 0, 6, 4, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "for x,labels in train_loader:\n",
    "    print('len(x):', len(x))\n",
    "    print('len(x[0][0]):', len(x[0][0]))\n",
    "    print('len(x[0][0][0]):', len(x[0][0][0]))\n",
    "    print('x:', x)\n",
    "    print('labels:', labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine a batch of images\n",
    "Use DataLoader, <tt>make_grid</tt> and matplotlib to display the first batch of 10 images.<br>\n",
    "OPTIONAL: display the labels as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [    6     6     0     1     7     2     1     9     2     8]\n",
      "Class:  Shirt Shirt T-shirt Trouser Sneaker Sweater Trouser Boot Sweater Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:5}')) # to widen the printed array\n",
    "\n",
    "# Grab the first batch of 10 images\n",
    "for images,labels in train_loader: \n",
    "    break\n",
    "\n",
    "# Print the labels\n",
    "print('Label:', labels.numpy())\n",
    "print('Class: ', *np.array([class_names[i] for i in labels]))\n",
    "\n",
    "# Print the images\n",
    "im = make_grid(images, nrow=10)  # the default nrow is 8\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "<h3>3. If a 28x28 image is passed through a Convolutional layer using a 5x5 filter, a step size of 1, and no padding, what is the resulting matrix size?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig size: torch.Size([10, 1, 28, 28])\n",
      "Down size: torch.Size([10, 1, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(1, 1, 5, 1)\n",
    "for x,labels in train_loader:\n",
    "    print('Orig size:',x.shape)\n",
    "    break\n",
    "x = conv(x)\n",
    "print('Down size:',x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. If the sample from question 3 is then passed through a 2x2 MaxPooling layer, what is the resulting matrix size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border:1px black solid; padding:5px'>\n",
    "24 / 2 = 12\n",
    "<br> Result = 12 x 12\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down size: torch.Size([10, 1, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "# Run the code below to check your answer:\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print('Down size:',x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN definition\n",
    "### 5. Define a convolutional neural network\n",
    "Define a CNN model that can be trained on the Fashion-MNIST dataset. The model should contain two convolutional layers, two pooling layers, and two fully connected layers. You can use any number of neurons per layer so long as the model takes in a 28x28 image and returns an output of 10. Portions of the definition have been filled in for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set up the convolutional layers with \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        \n",
    "        # Set up the fully connected layers with torch.nn.Linear() \n",
    "        self.fc1 = nn.Linear(5*5*16, 100) # 100 neurons \n",
    "        self.fc2 = nn.Linear(100, 10) # 10 neurons (output)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        \n",
    "        # Flatten data\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "model = ConvolutionalNetwork()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the total number of trainable parameters (weights & biases) in the model above?\n",
    "Answers will vary depending on your model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border:1px black solid; padding:5px'>\n",
    "$\\quad\\begin{split}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times100)+100+(100\\times10)+10 &=\\\\\n",
    "54+6+864+16+40000+100+1000+10 &= 42,050\\end{split}$<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 40000\n",
      "   100\n",
      "  1000\n",
      "    10\n",
      "______\n",
      " 42050\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define loss function & optimizer\n",
    "Define a loss function called \"criterion\" and an optimizer called \"optimizer\".<br>\n",
    "You can use any functions you want, although we used Cross Entropy Loss and Adam (learning rate of 0.001) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train the model\n",
    "Don't worry about tracking loss values, displaying results, or validating the test set. Just train the model through 5 epochs. We'll evaluate the trained model in the next step.<br>\n",
    "OPTIONAL: print something after each epoch to indicate training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.43093926  accuracy:  79.642%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.31992337  accuracy:  85.787%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.63432688  accuracy:  87.687%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.30498973  accuracy:  88.667%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.28301722  accuracy:  89.363%\n",
      "\n",
      "Duration: 326 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # torch.max gets the max probability along axis 1. That's what the 1 in max bracket is for\n",
    "        # [1] index brings the label corresponding to the highest probability\n",
    "        # Returns predicted labels for a batch\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        \n",
    "        # Tally the number of correct predictions\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        # Gradients accumulate with every backprop. \n",
    "        # To prevent compounding we need to reset the stored gradient for each new epoch.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%6000 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluate the model\n",
    "Set <tt>model.eval()</tt> and determine the percentage correct out of 10,000 total test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 8848/10000 =  88.480%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
