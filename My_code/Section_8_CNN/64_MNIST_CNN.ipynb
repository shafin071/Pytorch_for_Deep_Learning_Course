{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Code Along with CNN\n",
    "Now that we've seen the results of an artificial neural network model on the <a href='https://en.wikipedia.org/wiki/MNIST_database'>MNIST dataset</a>, let's work the same data with a <a href='https://en.wikipedia.org/wiki/Convolutional_neural_network'>Convolutional Neural Network</a> (CNN).\n",
    "Make sure to watch the theory lectures! You'll want to be comfortable with:\n",
    "* convolutional layers\n",
    "* filters/kernels\n",
    "* pooling\n",
    "* depth, stride and zero-padding\n",
    "\n",
    "Note that in this exercise there is no need to flatten the MNIST data, as a CNN expects 2-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset\n",
    "PyTorch makes the MNIST train and test datasets available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. The first time they're called, the datasets will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download.\n",
    "\n",
    "Refer to the previous section for explanations of transformations, batch sizes and <a href='https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader'><tt><strong>DataLoader</strong></tt></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transform\n",
    "As part of the loading process, we can apply multiple transformations (reshape, convert to tensor, normalize, etc.) to the incoming data.<br>For this exercise we only need to convert images to tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ../Data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ../Data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loaders\n",
    "When working with images, we want relatively small batches; a batch size of 4 is not uncommon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional model\n",
    "In the previous section we used only fully connected layers, with an input layer of 784 (our flattened 28x28 images), hidden layers of 120 and 84 neurons, and an output size representing 10 possible digits.\n",
    "\n",
    "This time we'll employ two convolutional layers and two pooling layers before feeding data through fully connected hidden layers to our output. The model follows CONV/RELU/POOL/CONV/RELU/POOL/FC/RELU/FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take.</strong><br>\n",
    "\n",
    "1. Extend the base Module class:\n",
    "   \n",
    "<tt><font color=black>class ConvolutionalNetwork(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the convolutional layers with <a href='https://pytorch.org/docs/stable/nn.html#conv2d'><tt><strong>torch.nn.Conv2d()</strong></tt></a><br><br>The first layer has one input channel (the grayscale color channel). We'll assign 6 output channels for feature extraction. We'll set our kernel size to 3 to make a 3x3 filter, and set the step size to 1.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv1 = nn.Conv2d(1, 6, 3, 1)</font></tt><br>\n",
    "The second layer will take our 6 input channels and deliver 16 output channels.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv2 = nn.Conv2d(6, 16, 3, 1)</font></tt><br><br>\n",
    "\n",
    "3. Set up the fully connected layers with <a href='https://pytorch.org/docs/stable/nn.html#linear'><tt><strong>torch.nn.Linear()</strong></tt></a>.<br><br>The input size of (5x5x16) is determined by the effect of our kernels on the input image size. A 3x3 filter applied to a 28x28 image leaves a 1-pixel edge on all four sides. In one layer the size changes from 28x28 to 26x26. We could address this with zero-padding, but since an MNIST image is mostly black at the edges, we should be safe ignoring these pixels. We'll apply the kernel twice, and apply pooling layers twice, so our resulting output will be \n",
    "$\\;(((28-2)/2)-2)/2 = 5.5\\;$ which rounds down to 5 pixels per side.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc1 = nn.Linear(5\\*5\\*16, 120)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc2 = nn.Linear(120, 84)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc3 = nn.Linear(84, 10)</font></tt><br>\n",
    "See below for a more detailed look at this step.<br><br>\n",
    "\n",
    "4. Define the forward method.<br><br>Activations can be applied to the convolutions in one line using <a href='https://pytorch.org/docs/stable/nn.html#id27'><tt><strong>F.relu()</strong></tt></a> and pooling is done using <a href='https://pytorch.org/docs/stable/nn.html#maxpool2d'><tt><strong>F.max_pool2d()</strong></tt></a><br>\n",
    "<tt><font color=black>def forward(self, X):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv2(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "</font></tt>Flatten the data for the fully connected layers:<br><tt><font color=black>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = X.view(-1, 5\\*5\\*16)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.fc1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = self.fc2(X)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return F.log_softmax(X, dim=1)</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the convolutional layers</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "\n",
    "# 1 color channel\n",
    "# 6 filters (output channels). arbitrarily chosen\n",
    "# Kernel size 3 means 3x3 image kernel\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1) # ---> 6 filters ---> pooling ---> conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 input filters from conv1\n",
    "# 16 filters (output channels). arbitrarily chosen\n",
    "# Kernel size 3 means 3x3 image kernel\n",
    "\n",
    "conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first MNIST record (1st image)\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank-4 tensor to be passed into the model because this is what CNN expects\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 color channel, 6 filters <br>\n",
    "26, 26 because the image lost some border pixels since we applied an image kernel with no padding added<br>\n",
    "With MNIST dataset, all the numbers are centered in the image so we can afford to lose a few border pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Run the first pooling layer\n",
    "\n",
    "# F.max_pool2d(image tensor=x, kernel size=2, stride=2)\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor after pooling will result in the image dimension being halved as we chose max_pool2d kernel size and stride = 2 <br>\n",
    "<b>Remember:</b> max_pool2d means the image kernel will take the max pixel value per window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data before passing it into the fully connected hidden layers\n",
    "\n",
    "# Note: 16x5x5 is due to the tensor shape after 2nd pooling\n",
    "# -1 means whatever the size is\n",
    "x = x.view(-1, 16*5*5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the convolution output is passed into the fully connected layers.</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set up the convolutional layers with \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        \n",
    "       \n",
    "        # Set up the fully connected layers with torch.nn.Linear() \n",
    "        self.fc1 = nn.Linear(5*5*16, 120) # 120 neurons \n",
    "        self.fc2 = nn.Linear(120, 84) # 84 neurons\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 neurons (output)\n",
    "        \n",
    "    # Activations can be applied to the convolutions in one line using F.relu()\n",
    "    # Pooling is done using F.max_pool2d()\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        \n",
    "        # Flatten the data for the fully connected layers:\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 48000\n",
      "   120\n",
      " 10080\n",
      "    84\n",
      "   840\n",
      "    10\n",
      "______\n",
      " 60074\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refer to the model print:\n",
    "\n",
    "first layer (conv1) is 54 because (1 x 6 x 3 x 3) <br>\n",
    "Then add 6 because of 6 bias terms <br>\n",
    "Repeat for next layer.... <br>\n",
    "Pooling layers doesn't need any parameters <br>\n",
    "<br>\n",
    "\n",
    "No. of params for 1 CNN layer = (num_input x num_output x (kernel size)^2) + num_output(this is bias)\n",
    "\n",
    "I don't understand the multiplication part completely. I'll come back to it when I know more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the bias terms for each layer, the total number of parameters being trained is:<br>\n",
    "\n",
    "$\\quad\\begin{split}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times120)+120+(120\\times84)+84+(84\\times10)+10 &=\\\\\n",
    "54+6+864+16+48000+120+10080+84+840+10 &= 60,074\\end{split}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much less than MNIST ANN model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "This time we'll feed the data directly into the model without flattening it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.23029979  accuracy:  76.783%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.41337937  accuracy:  84.983%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.05105906  accuracy:  88.356%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.03533888  accuracy:  90.254%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.00846628  accuracy:  91.437%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.01381163  accuracy:  92.283%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.04235141  accuracy:  92.933%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.00684505  accuracy:  93.483%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00026164  accuracy:  93.889%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.00339690  accuracy:  94.230%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.01901418  accuracy:  98.050%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.06542295  accuracy:  97.858%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.24088362  accuracy:  97.772%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00181992  accuracy:  97.862%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00110789  accuracy:  97.823%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.07190584  accuracy:  97.872%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.01510326  accuracy:  97.912%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.14604968  accuracy:  97.938%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.02220620  accuracy:  97.981%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.00996184  accuracy:  97.993%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00197295  accuracy:  98.617%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00221097  accuracy:  98.500%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00028129  accuracy:  98.500%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.00086595  accuracy:  98.496%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.00215665  accuracy:  98.490%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00073557  accuracy:  98.525%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00139412  accuracy:  98.526%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00101156  accuracy:  98.546%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00602059  accuracy:  98.578%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00011250  accuracy:  98.582%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.00716558  accuracy:  99.033%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.00336675  accuracy:  98.875%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.03002850  accuracy:  98.878%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.02434119  accuracy:  98.879%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.00012254  accuracy:  98.897%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.00236857  accuracy:  98.883%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00307822  accuracy:  98.855%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.00073611  accuracy:  98.898%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00486819  accuracy:  98.906%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00087461  accuracy:  98.878%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00133597  accuracy:  99.183%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.09540218  accuracy:  99.150%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00066916  accuracy:  99.178%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00058618  accuracy:  99.142%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.03608703  accuracy:  99.103%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.00807527  accuracy:  99.108%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00387011  accuracy:  99.079%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00037396  accuracy:  99.104%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.33812284  accuracy:  99.109%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00038514  accuracy:  99.072%\n",
      "\n",
      "Duration: 368 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # torch.max gets the max probability along axis 1. That's what the 1 in max bracket is for\n",
    "        # [1] index brings the label corresponding to the highest probability\n",
    "        # Returns predicted labels for a batch\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        \n",
    "        # Tally the number of correct predictions\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        # Gradients accumulate with every backprop. \n",
    "        # To prevent compounding we need to reset the stored gradient for each new epoch.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss increases after 3 epochs means there's overfitting if we training further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9874/10000 =  98.740%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our [784,120,84,10] ANN returned an accuracy of 97.25% after 10 epochs. And it used 105,214 parameters to our current 60,074."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 978    1    5    1    0    2    7    0   10    0]\n",
      " [   0 1130    3    2    0    0    1    5    0    1]\n",
      " [   0    0 1015    0    1    0    0    7    0    0]\n",
      " [   0    1    1 1004    0    9    0    1    1    2]\n",
      " [   0    0    0    0  963    0    1    1    0    1]\n",
      " [   0    0    0    0    0  873    2    0    0    2]\n",
      " [   2    1    1    0    4    1  944    0    0    0]\n",
      " [   0    0    4    1    1    0    0 1005    0    1]\n",
      " [   0    2    3    2    2    1    3    1  961    1]\n",
      " [   0    0    0    0   11    6    0    8    2 1001]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 175,  247,  320,  340,  412,  445,  460,  495,  619,  646],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [ 175  247  320  340  412  445  460  495  619  646  659  667]\n",
      "Label: [   7    4    9    5    5    6    5    8    1    2    2    7]\n",
      "Guess: [   1    2    8    3    3    0    9    0    8    6    1    1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a new image through the model\n",
    "We can also pass a single image through the model to obtain a prediction.\n",
    "Pick a number from 0 to 9999, assign it to \"x\", and we'll use that value to select a number from the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2019  # random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.3059, 0.6078,\n",
       "           1.0000, 1.0000, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.8941, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.3098, 0.9294, 0.9922, 0.9922, 0.9843,\n",
       "           0.8706, 0.5451, 0.4941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3725, 0.9020, 0.9922, 0.8863, 0.8235, 0.2235,\n",
       "           0.0000, 0.0000, 0.3490, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0353, 0.8980, 0.9922, 0.8078, 0.0902, 0.0000, 0.0000,\n",
       "           0.0784, 0.4863, 0.9843, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.6235, 0.9922, 0.9804, 0.1216, 0.0118, 0.2000, 0.6471,\n",
       "           0.5882, 0.9922, 0.9922, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0627, 0.9098, 0.9922, 0.7176, 0.2196, 0.6941, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.9725, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3216, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8196,\n",
       "           0.7333, 0.9922, 0.7412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3216, 0.9922, 0.9922, 0.9922, 0.9882, 0.8392, 0.1725, 0.0471,\n",
       "           0.6431, 0.9922, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.2510, 0.7804, 0.7804, 0.6353, 0.3373, 0.0000, 0.0000, 0.1765,\n",
       "           0.9922, 0.9137, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5098,\n",
       "           0.9922, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9098,\n",
       "           0.7725, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9725,\n",
       "           0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7059, 0.9608,\n",
       "           0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8627,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.8392, 0.4863,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.9922, 0.4863,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6275, 0.9922, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.8902, 0.9922, 0.0627,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.8392, 0.5020, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contains 28 main arrays, each array with 28 elements\n",
    "# Thus representing a 28 x 28 pixels of an image\n",
    "# At the end, it also has the label, which is 9 in this case\n",
    "test_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[x][0].reshape((28,28)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Remember to reshape your test data with .view(batch_size, no._color_channel, pixel_height, pixel_width)\n",
    "    # CNN model requires\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
